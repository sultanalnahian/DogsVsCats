{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import logging\n",
    "import csv\n",
    "logging.basicConfig(filename='Log\\\\inception_v3.log',level=logging.DEBUG, format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "from tflearn.layers.normalization import batch_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'train'\n",
    "TEST_DIR = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inception_model_dir = \"PretrainedModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_list = os.listdir(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Feature from Pretrined Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "  with tf.gfile.FastGFile(os.path.join(inception_model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(list_images, image_dir):\n",
    "    nb_features = 2048\n",
    "    features = np.empty((len(list_images),nb_features))\n",
    "    labels = []\n",
    "    create_graph()\n",
    "    with tf.Session() as sess:\n",
    "        next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "        for ind, image in enumerate(list_images):\n",
    "            try:\n",
    "                path = os.path.join(image_dir,image)\n",
    "                if (ind%100 == 0):\n",
    "                    print('%d Processing %s...'  %(ind, image))\n",
    "                if not gfile.Exists(path):\n",
    "                    print('File does not exist %s', image)\n",
    "                    tf.logging.fatal('File does not exist %s', image)\n",
    "\n",
    "                image_data = gfile.FastGFile(path, 'rb').read()\n",
    "                predictions = sess.run(next_to_last_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "                features[ind,:] = np.squeeze(predictions)\n",
    "                labels.append(image.split('.')[0])\n",
    "            except Exception as e:\n",
    "                logging.error(\"Processing failed for %s\", image)\n",
    "                print (e)\n",
    "                \n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Features and Labels for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features,labels = extract_features(image_list, TRAIN_DIR)\n",
    "print(\"Processing Completed\")\n",
    "pickle.dump(features, open('inception_features', 'wb'))\n",
    "pickle.dump(labels, open('inception_labels', 'wb'))\n",
    "print(\"Pickle file saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Convert Class Label to One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(word_label):\n",
    "    if word_label == 'cat': return [1,0]\n",
    "    elif word_label == 'dog': return [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Features and Label of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_train = pickle.load(open('inception_features', 'rb'))\n",
    "labels_train = pickle.load(open('inception_labels', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hot_labels_train = []\n",
    "for label in labels_train:\n",
    "    one_hot = one_hot_encode(label)\n",
    "    one_hot_labels_train.append(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Training Data Set Into Train and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, y_validation = cross_validation.train_test_split(features_train, one_hot_labels_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Final Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BOTTLENECK_TENSOR_SIZE = 2048\n",
    "class_count = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = tflearn.input_data(shape=[None, BOTTLENECK_TENSOR_SIZE])\n",
    "net = tflearn.fully_connected(net, 1024, activation = 'elu')\n",
    "net = tflearn.fully_connected(net, 64, activation = 'elu')\n",
    "net = tflearn.fully_connected(net, class_count, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='momentum', loss='categorical_crossentropy', learning_rate=0.001)\n",
    "\n",
    "model = tflearn.DNN(net, \n",
    "                    checkpoint_path='trained_model/fine_tune_inception/inception_v3.ckpt', \n",
    "                    tensorboard_verbose=3, max_checkpoints = 10,\n",
    "                   tensorboard_dir = 'tensor_board')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 15649  | total loss: \u001b[1m\u001b[32m0.00566\u001b[0m\u001b[0m | time: 78.162s\n",
      "| Momentum | epoch: 050 | loss: 0.00566 - acc: 0.9999 -- iter: 19968/20000\n",
      "Training Step: 15650  | total loss: \u001b[1m\u001b[32m0.00522\u001b[0m\u001b[0m | time: 79.562s\n",
      "| Momentum | epoch: 050 | loss: 0.00522 - acc: 0.9999 | val_loss: 0.01647 - val_acc: 0.9952 -- iter: 20000/20000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, n_epoch = 50, validation_set = (X_validation, y_validation), show_metric = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('trained_model/tuned_inception_v3_model_momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load the Fine-tuned Inception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load('trained_model/tuned_inception_v3_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features for Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features, test_labels = extract_features(test_imageList, TEST_DIR)\n",
    "print(\"Processing Completed\")\n",
    "pickle.dump(test_features, open('test_inception_features', 'wb'))\n",
    "pickle.dump(test_labels, open('test_inception_labels', 'wb'))\n",
    "print(\"Pickle file saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features and Labels for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_test = pickle.load(open('test_inception_features', 'rb'))\n",
    "labels_test = pickle.load(open('test_inception_labels', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create the Submission File for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = list(zip(map(int,labels_test),prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l  =sorted(l,key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l =list(map(lambda x:(x[0],x[1][1]),l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_dataset = len(labels_test)\n",
    "output = []\n",
    "outputFile = open(\"classification_report.csv\", \"w\", newline = '')\n",
    "fieldNames = [\"id\", \"label\"]\n",
    "outputFileWriter = csv.DictWriter(outputFile, fieldnames = fieldNames, delimiter = ',')\n",
    "outputFileWriter.writeheader()\n",
    "for item in l:\n",
    "    rowForWrite = {\"id\":item[0], \"label\":item[1]}\n",
    "    outputFileWriter.writerow(rowForWrite)\n",
    "    \n",
    "outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
